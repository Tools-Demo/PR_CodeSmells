{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.logspace(0,-9, num=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "from xgboost import plot_importance\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "import time as t\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Dataset/25_projects_PRs.csv\", sep=',', encoding='utf-8')\n",
    "\n",
    "\n",
    "# #for HP tuning\n",
    "# def get_classifiers_without_params():\n",
    "#     return {\n",
    "#         'MLP': MLPClassifier(max_iter=100),\n",
    "#         'RandomForest': RandomForestClassifier(bootstrap=False, class_weight='balanced'),\n",
    "#         'LinearSVC': LinearSVC(max_iter=2000),\n",
    "#         'LogisticRegression': LogisticRegression(multi_class='auto', max_iter=1200),\n",
    "#         'XGBoost': xgb.XGBClassifier(objective = 'binary:logistic', eval_metric = 'auc', seed = 201703, missing = 1),\n",
    "#         'BaggedDT': BaggingClassifier(),\n",
    "#         'NaiveBayes': GaussianNB(),\n",
    "#         'KNN': KNeighborsClassifier()\n",
    "        \n",
    "#     }\n",
    "\n",
    "\n",
    "# # with HP tuning\n",
    "# def get_classifiers():\n",
    "#     return {\n",
    "#         'RandomForest': RandomForestClassifier(n_jobs=-1, n_estimators=1000, max_features='sqrt',bootstrap=False, class_weight='balanced'),\n",
    "#         'LinearSVC': LinearSVC(max_iter=2000,C = 1),\n",
    "#         'LogisticRegression': LogisticRegression(C = 100, penalty = 'l2', solver= 'lbfgs', n_jobs=4, multi_class='auto', max_iter=1200),\n",
    "#         'XGBoost': xgb.XGBClassifier(**params), #max_depth=11, min_child_weight=9,\n",
    "#         'MLP': MLPClassifier(max_iter=100, activation='tanh', alpha=0.0001, hidden_layer_sizes=(50, 100, 50), learning_rate='adaptive', solver='adam')\n",
    "#         'BaggedDT': BaggingClassifier(n_estimators = 1000),\n",
    "#         'NaiveBayes': GaussianNB(var_smoothing = 1.00E-09),\n",
    "#         'KNN': KNeighborsClassifier(metric = 'manhattan', n_neighbors=19, weights='distance') \n",
    "#     }\n",
    "\n",
    "# params = {\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'colsample_bytree': 0.2,\n",
    "#     'max_depth': 9,\n",
    "#     'gamma': 0.1,\n",
    "#     'verbose_eval': True,\n",
    "#     'eval_metric': 'auc',\n",
    "#     'seed': 201703,\n",
    "#     'missing':-1,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'n_estimators': 150,   \n",
    "# }\n",
    "\n",
    "# # without HP tuning\n",
    "# def get_classifiers():\n",
    "#     return {\n",
    "#         'RandomForest': RandomForestClassifier(bootstrap=False, class_weight='balanced'),          \n",
    "#         'LinearSVC': LinearSVC(max_iter=2000),\n",
    "#         'LogisticRegression': LogisticRegression(multi_class='auto', max_iter=1200),\n",
    "#         'XGBoost': xgb.XGBClassifier(objective = 'binary:logistic', eval_metric = 'auc', seed = 201703, missing = 1),\n",
    "#         'MLP': MLPClassifier(max_iter=100),    \n",
    "#         'BaggedDT': BaggingClassifier(),\n",
    "#         'NaiveBayes': GaussianNB(),\n",
    "#         'KNN': KNeighborsClassifier()\n",
    "#     }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def encode_labels(df1, column_name):\n",
    "    encoder = LabelEncoder()\n",
    "    df1[column_name] = [str(label) for label in df1[column_name]]\n",
    "    encoder.fit(df1[column_name])\n",
    "    one_hot_vector = encoder.transform(df1[column_name])\n",
    "    return one_hot_vector\n",
    "\n",
    "df['Language'] = encode_labels(df, 'Language')\n",
    "# df['Project_Domain'] = encode_labels(df, 'Project_Domain')\n",
    "df['src_churn'] = df['Additions'] + df['Deletions']\n",
    "df['num_comments'] = df['Review_Comments_Count'] + df['Comments_Count']\n",
    "df['is_God_Class'] = df['GodClass'].apply(lambda x: 1 if x>0 else 0)\n",
    "df['is_Data_Class'] = df['DataClass'].apply(lambda x: 1 if x>0 else 0)\n",
    "df['is_Long_Method'] = df['ExcessiveMethodLength'].apply(lambda x: 1 if x>0 else 0)\n",
    "df['is_Long_Parameter_List'] = df['ExcessiveParameterList'].apply(lambda x: 1 if x>0 else 0)\n",
    "df.loc[(df['GodClass'] > 0) | (df['DataClass'] > 0) | (df['ExcessiveMethodLength'] > 0) |\n",
    "       (df['ExcessiveParameterList'] > 0), 'is_smelly'] = 1\n",
    "df.loc[df['is_smelly'].isnull(), 'is_smelly'] = 0\n",
    "\n",
    "project_features = ['Project_Age', 'Team_Size', 'Stars', 'File_Touched_Average', 'Forks_Count', 'Watchers', 'Language',\n",
    "                    'Project_Domain', 'Contributor_Num', 'Comments_Per_Closed_PR', 'Additions_Per_Week', 'Deletions_Per_Week',\n",
    "                    'Merge_Latency', 'Comments_Per_Merged_PR', 'Churn_Average', 'Close_Latency', 'Project_Accept_Rate',\n",
    "                    'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Workload', 'Commits_Average',\n",
    "                    'Open_Issues', 'PR_Time_Created_At', 'PR_Date_Closed_At', 'PR_Time_Closed_At', 'PR_Date_Created_At',\n",
    "                    'Project_Name', 'PR_accept']\n",
    "PR_features = ['Intra_Branch', 'Assignees_Count', 'Label_Count', 'Files_Changed', 'Contain_Fix_Bug', 'Wait_Time', 'Day',\n",
    "               'src_churn', 'Deletions', 'Commits_PR', 'first_response_time', 'first_response',\n",
    "               'latency_after_first_response', 'conflict', 'X1_0', 'X1_1', 'X1_2', 'X1_3', 'X1_4', 'X1_5', 'X1_6', 'X1_7',\n",
    "               'X1_8', 'X1_9', 'PR_Latency', 'title_words_count', 'body_words_count','Point_To_IssueOrPR', 'PR_Time_Created_At',\n",
    "               'PR_Date_Closed_At', 'PR_Time_Closed_At', 'PR_Date_Created_At', 'Project_Name', 'PR_accept']\n",
    "integrator_features = ['Participants_Count', 'num_comments', 'Last_Comment_Mention',\n",
    "                       'line_comments_count', 'comments_reviews_words_count', 'PR_Time_Created_At', 'PR_Date_Closed_At',\n",
    "                       'PR_Time_Closed_At', 'PR_Date_Created_At', 'Project_Name', 'PR_accept']\n",
    "contributor_features = ['Followers', 'Closed_Num', 'Contributor', 'Public_Repos', 'Organization_Core_Member',\n",
    "                        'Contributions', 'User_Accept_Rate', 'Accept_Num', 'Closed_Num_Rate', 'Prev_PRs', 'Following',\n",
    "                        'PR_Time_Created_At', 'PR_Date_Closed_At', 'PR_Time_Closed_At', 'PR_Date_Created_At',\n",
    "                        'Project_Name', 'PR_accept']\n",
    "quality_features = ['AbstractClassWithoutAbstractMethod', 'AccessorClassGeneration', 'AccessorMethodGeneration',\n",
    "                     'ArrayIsStoredDirectly', 'AvoidMessageDigestField', 'AvoidPrintStackTrace',\n",
    "                     'AvoidReassigningLoopVariables', 'AvoidReassigningParameters', 'AvoidStringBufferField',\n",
    "                     'AvoidUsingHardCodedIP', 'CheckResultSet', 'ConstantsInInterface',\n",
    "                     'DefaultLabelNotLastInSwitchStmt', 'DoubleBraceInitialization', 'ForLoopCanBeForeach',\n",
    "                     'ForLoopVariableCount', 'GuardLogStatement', 'JUnit4SuitesShouldUseSuiteAnnotation',\n",
    "                     'JUnit4TestShouldUseAfterAnnotation', 'JUnit4TestShouldUseBeforeAnnotation',\n",
    "                     'JUnit4TestShouldUseTestAnnotation', 'JUnitAssertionsShouldIncludeMessage',\n",
    "                     'JUnitTestContainsTooManyAsserts', 'JUnitTestsShouldIncludeAssert', 'JUnitUseExpected',\n",
    "                     'LiteralsFirstInComparisons', 'LooseCoupling', 'MethodReturnsInternalArray', 'MissingOverride',\n",
    "                     'OneDeclarationPerLine', 'PositionLiteralsFirstInCaseInsensitiveComparisons',\n",
    "                     'PositionLiteralsFirstInComparisons', 'PreserveStackTrace', 'ReplaceEnumerationWithIterator',\n",
    "                     'ReplaceHashtableWithMap', 'ReplaceVectorWithList', 'SwitchStmtsShouldHaveDefault',\n",
    "                     'SystemPrintln', 'UnusedFormalParameter', 'UnusedImports', 'UnusedLocalVariable',\n",
    "                     'UnusedPrivateField', 'UnusedPrivateMethod', 'UseAssertEqualsInsteadOfAssertTrue',\n",
    "                     'UseAssertNullInsteadOfAssertTrue', 'UseAssertSameInsteadOfAssertTrue',\n",
    "                     'UseAssertTrueInsteadOfAssertEquals', 'UseCollectionIsEmpty', 'UseTryWithResources', 'UseVarargs',\n",
    "                     'WhileLoopWithLiteralBoolean', 'AbstractNaming', 'AtLeastOneConstructor', 'AvoidDollarSigns',\n",
    "                     'AvoidFinalLocalVariable', 'AvoidPrefixingMethodParameters', 'AvoidProtectedFieldInFinalClass',\n",
    "                     'AvoidProtectedMethodInFinalClassNotExtending', 'AvoidUsingNativeCode', 'BooleanGetMethodName',\n",
    "                     'CallSuperInConstructor', 'ClassNamingConventions', 'CommentDefaultAccessModifier',\n",
    "                     'ConfusingTernary', 'ControlStatementBraces', 'DefaultPackage', 'DontImportJavaLang',\n",
    "                     'DuplicateImports', 'EmptyMethodInAbstractClassShouldBeAbstract', 'ExtendsObject',\n",
    "                     'FieldDeclarationsShouldBeAtStartOfClass', 'FieldNamingConventions', 'ForLoopShouldBeWhileLoop',\n",
    "                     'ForLoopsMustUseBraces', 'FormalParameterNamingConventions', 'GenericsNaming',\n",
    "                     'IdenticalCatchBranches', 'IfElseStmtsMustUseBraces', 'IfStmtsMustUseBraces', 'LinguisticNaming',\n",
    "                     'LocalHomeNamingConvention', 'LocalInterfaceSessionNamingConvention', 'LocalVariableCouldBeFinal',\n",
    "                     'LocalVariableNamingConventions', 'LongVariable', 'MDBAndSessionBeanNamingConvention',\n",
    "                     'MethodArgumentCouldBeFinal', 'MethodNamingConventions', 'MIsLeadingVariableName', 'NoPackage',\n",
    "                     'UseUnderscoresInNumericLiterals', 'OnlyOneReturn', 'PackageCase', 'PrematureDeclaration',\n",
    "                     'RemoteInterfaceNamingConvention', 'RemoteSessionInterfaceNamingConvention', 'ShortClassName',\n",
    "                     'ShortMethodName', 'ShortVariable', 'SuspiciousConstantFieldName', 'TooManyStaticImports',\n",
    "                     'UnnecessaryAnnotationValueElement', 'UnnecessaryConstructor', 'UnnecessaryFullyQualifiedName',\n",
    "                     'UnnecessaryLocalBeforeReturn', 'UnnecessaryModifier', 'UnnecessaryReturn', 'UseDiamondOperator',\n",
    "                     'UselessParentheses', 'UselessQualifiedThis', 'UseShortArrayInitializer',\n",
    "                     'VariableNamingConventions', 'WhileLoopsMustUseBraces', 'AbstractClassWithoutAnyMethod',\n",
    "                     'AvoidCatchingGenericException', 'AvoidDeeplyNestedIfStmts', 'AvoidRethrowingException',\n",
    "                     'AvoidThrowingNewInstanceOfSameException', 'AvoidThrowingNullPointerException',\n",
    "                     'AvoidThrowingRawExceptionTypes', 'AvoidUncheckedExceptionsInSignatures',\n",
    "                     'ClassWithOnlyPrivateConstructorsShouldBeFinal', 'CollapsibleIfStatements',\n",
    "                     'CouplingBetweenObjects', 'CyclomaticComplexity', 'DataClass', 'DoNotExtendJavaLangError',\n",
    "                     'ExceptionAsFlowControl', 'ExcessiveClassLength', 'ExcessiveImports', 'ExcessiveMethodLength',\n",
    "                     'ExcessiveParameterList', 'ExcessivePublicCount', 'FinalFieldCouldBeStatic', 'GodClass',\n",
    "                     'ImmutableField', 'LawOfDemeter', 'LogicInversion', 'LoosePackageCoupling',\n",
    "                     'ModifiedCyclomaticComplexity', 'NcssConstructorCount', 'NcssCount', 'NcssMethodCount',\n",
    "                     'NcssTypeCount', 'NPathComplexity', 'SignatureDeclareThrowsException', 'SimplifiedTernary',\n",
    "                     'SimplifyBooleanAssertion', 'SimplifyBooleanExpressions', 'SimplifyBooleanReturns',\n",
    "                     'SimplifyConditional', 'SingularField', 'StdCyclomaticComplexity', 'SwitchDensity',\n",
    "                     'TooManyFields', 'TooManyMethods', 'UselessOverridingMethod', 'UseObjectForClearerAPI',\n",
    "                     'UseUtilityClass', 'AssignmentInOperand', 'AssignmentToNonFinalStatic',\n",
    "                     'AvoidAccessibilityAlteration', 'AvoidAssertAsIdentifier', 'AvoidBranchingStatementAsLastInLoop',\n",
    "                     'AvoidCallingFinalize', 'AvoidCatchingNPE', 'AvoidCatchingThrowable',\n",
    "                     'AvoidDecimalLiteralsInBigDecimalConstructor', 'AvoidDuplicateLiterals', 'AvoidEnumAsIdentifier',\n",
    "                     'AvoidFieldNameMatchingMethodName', 'AvoidFieldNameMatchingTypeName',\n",
    "                     'AvoidInstanceofChecksInCatchClause', 'AvoidLiteralsInIfCondition',\n",
    "                     'AvoidLosingExceptionInformation', 'AvoidMultipleUnaryOperators', 'AvoidUsingOctalValues',\n",
    "                     'BadComparison', 'BeanMembersShouldSerialize', 'BrokenNullCheck', 'CallSuperFirst',\n",
    "                     'CallSuperLast', 'CheckSkipResult', 'ClassCastExceptionWithToArray', 'CloneMethodMustBePublic',\n",
    "                     'CloneMethodMustImplementCloneable', 'CloneMethodReturnTypeMustMatchClassName',\n",
    "                     'CloneThrowsCloneNotSupportedException', 'CloseResource', 'CompareObjectsWithEquals',\n",
    "                     'ConstructorCallsOverridableMethod', 'DataflowAnomalyAnalysis', 'DetachedTestCase',\n",
    "                     'DoNotCallGarbageCollectionExplicitly', 'DoNotCallSystemExit', 'DoNotExtendJavaLangThrowable',\n",
    "                     'DoNotHardCodeSDCard', 'DoNotThrowExceptionInFinally', 'DontImportSun',\n",
    "                     'DontUseFloatTypeForLoopIndices', 'EmptyCatchBlock', 'EmptyFinalizer', 'EmptyFinallyBlock',\n",
    "                     'EmptyIfStmt', 'EmptyInitializer', 'EmptyStatementBlock', 'EmptyStatementNotInLoop',\n",
    "                     'EmptySwitchStatements', 'EmptySynchronizedBlock', 'EmptyTryBlock', 'EmptyWhileStmt', 'EqualsNull',\n",
    "                     'FinalizeDoesNotCallSuperFinalize', 'FinalizeOnlyCallsSuperFinalize', 'FinalizeOverloaded',\n",
    "                     'FinalizeShouldBeProtected', 'IdempotentOperations', 'ImportFromSamePackage',\n",
    "                     'InstantiationToGetClass', 'InvalidSlf4jMessageFormat', 'InvalidLogMessageFormat',\n",
    "                     'JumbledIncrementer', 'JUnitSpelling', 'JUnitStaticSuite', 'LoggerIsNotStaticFinal',\n",
    "                     'MethodWithSameNameAsEnclosingClass', 'MisplacedNullCheck', 'MissingBreakInSwitch',\n",
    "                     'MissingSerialVersionUID', 'MissingStaticMethodInNonInstantiatableClass', 'MoreThanOneLogger',\n",
    "                     'NonCaseLabelInSwitchStatement', 'NonStaticInitializer', 'NullAssignment',\n",
    "                     'OverrideBothEqualsAndHashcode', 'ProperCloneImplementation', 'ProperLogger',\n",
    "                     'ReturnEmptyArrayRatherThanNull', 'ReturnFromFinallyBlock', 'SimpleDateFormatNeedsLocale',\n",
    "                     'SingleMethodSingleton', 'SingletonClassReturningNewInstance', 'StaticEJBFieldShouldBeFinal',\n",
    "                     'StringBufferInstantiationWithChar', 'SuspiciousEqualsMethodName', 'SuspiciousHashcodeMethodName',\n",
    "                     'SuspiciousOctalEscape', 'TestClassWithoutTestCases', 'UnconditionalIfStatement',\n",
    "                     'UnnecessaryBooleanAssertion', 'UnnecessaryCaseChange', 'UnnecessaryConversionTemporary',\n",
    "                     'UnusedNullCheckInEquals', 'UseCorrectExceptionLogging', 'UseEqualsToCompareStrings',\n",
    "                     'UselessOperationOnImmutable', 'UseLocaleWithCaseConversions', 'UseProperClassLoader',\n",
    "                     'HardCodedCryptoKey', 'InsecureCryptoIv']\n",
    "all_features = ['Label_Count', 'Review_Comments_Count', 'Following', 'Stars', 'Contributions', 'Merge_Latency',\n",
    "                'Closed_Num_Rate', 'Followers',  'Workload', 'Wednesday', 'Closed_Num', 'Public_Repos', 'Comments_Count',\n",
    "                'Deletions_Per_Week', 'Contributor', 'File_Touched_Average', 'Forks_Count', 'Organization_Core_Member',\n",
    "                'Monday', 'Contain_Fix_Bug', 'src_churn', 'Team_Size', 'Last_Comment_Mention', 'Sunday',\n",
    "                'Thursday', 'Project_Age', 'Open_Issues', 'Intra_Branch', 'Saturday', 'Participants_Count',\n",
    "                'Comments_Per_Closed_PR', 'Watchers', 'Project_Accept_Rate', 'Point_To_IssueOrPR', 'Accept_Num',\n",
    "                'Close_Latency', 'Contributor_Num', 'Commits_Average', 'Assignees_Count', 'Friday', 'Commits_PR',\n",
    "                'Wait_Time', 'line_comments_count', 'Prev_PRs', 'Comments_Per_Merged_PR', 'Files_Changed', 'Day',\n",
    "                'Churn_Average', 'Language', 'Tuesday', 'Additions_Per_Week', 'User_Accept_Rate', 'X1_0', 'X1_1',\n",
    "                'X1_2', 'X1_3', 'X1_4', 'X1_5', 'X1_6',  'X1_7', 'X1_8', 'X1_9', 'PR_Latency', 'Project_Name',\n",
    "                'PR_Date_Created_At', 'PR_Time_Created_At', 'PR_Date_Closed_At',\n",
    "                'PR_Time_Closed_At', 'first_response_time', 'first_response', 'latency_after_first_response',\n",
    "                'title_words_count', 'body_words_count', 'comments_reviews_words_count', 'is_smelly', 'PR_accept'\n",
    "                 #'is_God_Class', 'is_Data_Class', #'Project_Domain',\n",
    "                ]\n",
    "\n",
    "# Previous work features\n",
    "accept_baseline = ['src_churn', 'Commits_PR', 'Files_Changed', 'num_comments','Followers','Participants_Count',\n",
    "                   'Team_Size', 'File_Touched_Average', 'Commits_Average', 'Prev_PRs', 'is_smelly', #'Project_Size',\n",
    "                   'User_Accept_Rate', 'PR_Time_Created_At', 'PR_Date_Closed_At', 'PR_Time_Closed_At',\n",
    "                   'PR_Date_Created_At', 'Project_Name', 'PR_accept']\n",
    "\n",
    "df = df[accept_baseline]\n",
    "target = 'is_smelly'\n",
    "\n",
    "\n",
    "predictors = [x for x in df.columns if x not in [target, 'PR_Date_Created_At', 'PR_Time_Created_At', 'PR_Date_Closed_At',\n",
    "                                                 'PR_Time_Closed_At', 'Project_Name', 'PR_accept']]\n",
    "\n",
    "predictors_with_label = [x for x in df.columns if x not in ['PR_accept', 'PR_Date_Created_At', 'PR_Time_Created_At',\n",
    "                                                            'Project_Name']]\n",
    "\n",
    "# Scale the training dataset: StandardScaler\n",
    "def scale_data_standardscaler(df_):\n",
    "    scaler_train =StandardScaler()\n",
    "    df_scaled = scaler_train.fit_transform(np.array(df_).astype('float64'))\n",
    "    df_scaled = pd.DataFrame(df_scaled, columns=predictors)\n",
    "\n",
    "    return df_scaled\n",
    "\n",
    "def extract_metric_from_report(report):\n",
    "    report = list(report.split(\"\\n\"))\n",
    "    report = report[-2].split(' ')\n",
    "    # print(report)\n",
    "    mylist = []\n",
    "    for i in range(len(report)):\n",
    "        if report[i] != '':\n",
    "            mylist.append(report[i])\n",
    "\n",
    "    return mylist[3], mylist[4], mylist[5]\n",
    "\n",
    "def extract_each_class_metric_from_report(report):\n",
    "    report = list(report.split(\"\\n\"))\n",
    "\n",
    "    mydict2 = {}\n",
    "    mydict = {}\n",
    "    index = 0\n",
    "    for line in range(len(report)):\n",
    "        if report[line] != '':\n",
    "            values_list = report[line].split(' ')\n",
    "            mydict[index] = values_list\n",
    "            index+=1\n",
    "    count=0\n",
    "    for value in mydict:\n",
    "        mylist = []\n",
    "        if value != 0:\n",
    "            for item in range(len(mydict[value])):\n",
    "                if mydict[value][item] != '':\n",
    "                    mylist.append(mydict[value][item])\n",
    "            mydict2[count] = mylist\n",
    "            count+=1\n",
    "    return mydict2[0], mydict2[1], mydict2[2], mydict2[3]\n",
    "\n",
    "def train_MLP_model(clf, x_train, y_train, x_test, name=None):\n",
    "    start_training_time = t.time()\n",
    "#     clf.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    clf.fit(x_train, y_train)\n",
    "    # test_loss, test_acc = model.evaluate(x_test, y_test)    \n",
    "    y_pred_train = clf.predict(x_train)\n",
    "    y_predprob_train = clf.predict_proba(x_train)[:, 1]\n",
    "    training_time = round(t.time() - start_training_time, 3)\n",
    "    print(f'Training time of the model: {training_time} seconds')\n",
    "    start_testing_time = t.time()\n",
    "    y_pred = clf.predict(x_test)\n",
    "    y_predprob = clf.predict_proba(x_test)[:, 1]\n",
    "    testing_time = round(t.time() - start_testing_time, 3)\n",
    "    print(f'Testing time of the model: {testing_time} seconds')\n",
    "    return y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time\n",
    "\n",
    "def train_XGB_feature_importance(clf, x_train, y_train):\n",
    "    clf = clf.fit(x_train, y_train, verbose=11)\n",
    "    # importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "    f_gain = clf.get_booster().get_score(importance_type='gain')\n",
    "    importance = sorted(f_gain.items(), key=operator.itemgetter(1))\n",
    "    print(importance)\n",
    "    df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "    df.to_csv('Results/features_fscore.csv', encoding='utf-8', index=True)\n",
    "\n",
    "def train_XGB_model(clf, x_train, y_train, x_test, name=None):\n",
    "    start_training_time = t.time()\n",
    "    clf = clf.fit(x_train, y_train, verbose=11)\n",
    "    # Save the model\n",
    "    # with open('Saved_Models/3_labels/xgb_selected_features.pickle.dat', 'wb') as f:\n",
    "    #     pickle.dump(clf, f)\n",
    "\n",
    "    # Load the model\n",
    "    # with open('response_xgb_16.pickle.dat', 'rb') as f:\n",
    "    #     load_xgb = pickle.load(f)\n",
    "\n",
    "    y_pred_train = clf.predict(x_train)\n",
    "    y_predprob_train = clf.predict_proba(x_train)[:, 1]\n",
    "    training_time = round(t.time() - start_training_time, 3)\n",
    "    print(f'Training time of the model: {training_time} seconds')\n",
    "    start_testing_time = t.time()\n",
    "    y_pred = clf.predict(x_test)\n",
    "    y_predprob = clf.predict_proba(x_test)[:, 1]\n",
    "    testing_time = round(t.time() - start_testing_time, 3)\n",
    "    print(f'Testing time of the model: {testing_time} seconds')\n",
    "\n",
    "    return y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time\n",
    "\n",
    "def train_SVM_model(clf, x_train, y_train, x_test, name=None):\n",
    "    start_training_time = t.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    svm = CalibratedClassifierCV(base_estimator=clf, cv='prefit')\n",
    "    svm.fit(x_train, y_train)\n",
    "\n",
    "    # with open('Saved_Models/3_labels/'+name+'.pickle.dat', 'wb') as f:\n",
    "    #     pickle.dump(clf, f)\n",
    "    # train\n",
    "    y_pred_train = svm.predict(x_train)\n",
    "    y_predprob_train = svm.predict_proba(x_train)[:, 1]\n",
    "    training_time = round(t.time() - start_training_time, 3)\n",
    "    print(f'Training time of the model: {training_time} seconds')\n",
    "    start_testing_time = t.time()\n",
    "    # test\n",
    "    y_pred = svm.predict(x_test)\n",
    "    y_predprob = svm.predict_proba(x_test)[:, 1]\n",
    "    testing_time = round(t.time() - start_testing_time, 3)\n",
    "    print(f'Testing time of the model: {testing_time} seconds')\n",
    "    return y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time\n",
    "\n",
    "def train_RF_LR_model(clf, x_train, y_train, x_test, name=None):\n",
    "    start_training_time = t.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    # with open('Saved_Models/3_labels/'+name+'.pickle.dat', 'wb') as f:\n",
    "    #     pickle.dump(clf, f)\n",
    "    # train\n",
    "    y_pred_train = clf.predict(x_train)\n",
    "    y_predprob_train = clf.predict_proba(x_train)[:, 1]\n",
    "    training_time = round(t.time() - start_training_time, 3)\n",
    "    print(f'Training time of the model: {training_time} seconds')\n",
    "    start_testing_time = t.time()\n",
    "    # test\n",
    "    y_pred = clf.predict(x_test)\n",
    "    y_predprob = clf.predict_proba(x_test)[:, 1]\n",
    "    testing_time = round(t.time() - start_testing_time, 3)\n",
    "    print(f'Testing time of the model: {testing_time} seconds')\n",
    "    return y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time\n",
    "\n",
    "\n",
    "def calcuate_average_of_10_folds_for_each_project(df):\n",
    "    avg_result = pd.DataFrame(columns=['Model', 'Project', 'AUC', 'neg_precision', 'pos_precision', 'neg_recall', 'pos_recall',\n",
    "                                    'neg_f_score', 'pos_f_score', 'Precision', 'Recall', 'F-Score', 'Test_Accuracy',\n",
    "                                    'Train_Accuracy', 'Training_time', 'Testing_time'])\n",
    "    classifiers = get_classifiers()\n",
    "    for project in df['Project_Name'].unique():\n",
    "        df_project = df.loc[df.Project_Name == project]\n",
    "        print('Project {} is under processing'.format(project))\n",
    "        for name, value in classifiers.items():\n",
    "            model_result = df_project.loc[df_project.Model == name]\n",
    "            avg_result = avg_result.append(\n",
    "                {'Model': name, 'Project': project,\n",
    "                 'AUC': model_result['AUC'].mean(),\n",
    "                 'neg_precision': model_result['neg_precision'].mean(),\n",
    "                 'pos_precision': model_result['pos_precision'].mean(),\n",
    "                 'neg_recall': model_result['neg_recall'].mean(),\n",
    "                 'pos_recall': model_result['pos_recall'].mean(),\n",
    "                 'neg_f_score': model_result['neg_f_score'].mean(),\n",
    "                 'pos_f_score': model_result['pos_f_score'].mean(),\n",
    "                 'Precision': model_result['Precision'].mean(),\n",
    "                 'Recall': model_result['Recall'].mean(),\n",
    "                 'F-Score': model_result['F-Score'].mean(),\n",
    "                 'Test_Accuracy': model_result['Test_Accuracy'].mean(),\n",
    "                 'Train_Accuracy': model_result['Train_Accuracy'].mean(),\n",
    "                 'Training_time': model_result['Training_time'].mean(),\n",
    "                 'Testing_time': model_result['Testing_time'].mean()},\n",
    "                ignore_index=True)\n",
    "    return avg_result\n",
    "\n",
    "def calcuate_average_of_10_folds(df):\n",
    "    # df = pd.read_csv('Results/results_10_fold_3.csv')\n",
    "    avg_result = pd.DataFrame(columns=['Model', 'Precision', 'Recall', 'F-measure', 'Test_Accuracy', 'Train_Accuracy'])\n",
    "    classifiers = get_classifiers()\n",
    "    for name, value in classifiers.items():\n",
    "        model_result = df.loc[df.Model == name]\n",
    "        avg_result = avg_result.append(\n",
    "            {'Model': name,\n",
    "             'Precision': model_result['Precision'].mean(),\n",
    "             'Recall': model_result['Recall'].mean(),\n",
    "             'F-measure': model_result['F-measure'].mean(),\n",
    "             'Test_Accuracy': model_result['Test_Accuracy'].mean(),\n",
    "             'Train_Accuracy': model_result['Train_Accuracy'].mean()},\n",
    "            ignore_index=True)\n",
    "    avg_result.to_csv('Results/results_10_fold_avg_3.csv', sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "def calcuate_average_of_10_folds_1():\n",
    "    df = pd.read_csv('Results/accept/results_projects_2.csv')\n",
    "    avg_result = pd.DataFrame(columns=['Model', 'AUC', 'neg_precision', 'pos_precision', 'neg_recall', 'pos_recall',\n",
    "                                    'neg_f_score', 'pos_f_score', 'Precision', 'Recall', 'F-Score', 'Test_Accuracy',\n",
    "                                    'Train_Accuracy'])\n",
    "    classifiers = get_classifiers()\n",
    "    for name, value in classifiers.items():\n",
    "        model_result = df.loc[df.Model == name]\n",
    "        avg_result = avg_result.append(\n",
    "            {'Model': name, 'AUC': model_result['AUC'].mean(),\n",
    "             'neg_precision': model_result['neg_precision'].mean(),\n",
    "             'pos_precision': model_result['pos_precision'].mean(),\n",
    "             'neg_recall': model_result['neg_recall'].mean(),\n",
    "             'pos_recall': model_result['pos_recall'].mean(),\n",
    "             'neg_f_score': model_result['neg_f_score'].mean(),\n",
    "             'pos_f_score': model_result['pos_f_score'].mean(),\n",
    "             'Precision': model_result['Precision'].mean(),\n",
    "             'Recall': model_result['Recall'].mean(),\n",
    "             'F-Score': model_result['F-Score'].mean(),\n",
    "             'Test_Accuracy': model_result['Test_Accuracy'].mean(),\n",
    "             'Train_Accuracy': model_result['Train_Accuracy'].mean()},\n",
    "            ignore_index=True)\n",
    "    avg_result.to_csv('Results/accept/results_project_avg_2.csv', sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "def extract_selected_features():\n",
    "    df_f = pd.read_csv('Results/accept/features_fscore_2.csv')\n",
    "    df_f = df_f.loc[df_f.fscore >= 15]\n",
    "    print(df_f.sort_values(by=['fscore']))\n",
    "    print(list(df_f.feature))\n",
    "    print(df_f.shape)\n",
    "\n",
    "def draw_features_barplot():\n",
    "    df = pd.read_csv(\"Results/accept/features_fscore_2.csv\", sep=\",\")\n",
    "    df = df.sort_values(by=['fscore'], ascending=False)\n",
    "    df = df[df.fscore >= 15]\n",
    "    print(len(df.feature))\n",
    "    print(list(df.feature))\n",
    "    fig, ax = plt.subplots(figsize=(8, 3))\n",
    "    df['fscore_log'] = np.log(df['fscore'])\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    sns.barplot(x=\"feature\", y=\"fscore_log\", data=df, ax=ax, palette=\"GnBu_d\") #palette=\"Blues_d\" GnBu_d ch:2.5,-.2,dark=.3\n",
    "    ax.xaxis.set_tick_params(labelsize=9)\n",
    "    ax.set_xlabel('Features')\n",
    "    ax.set_ylabel('Average Gain (log-scaled)')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig('Results/accept/plots/accept_SF_1.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def baseline_classifer(X, y):\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    start_training_time = t.time()\n",
    "    dummy_clf.fit(X, y)\n",
    "    training_time = round(t.time() - start_training_time, 3)\n",
    "    start_testing_time = t.time()\n",
    "    y_pred = dummy_clf.predict(X)\n",
    "    y_predprob = dummy_clf.predict_proba(X)[:, 1]\n",
    "    testing_time = round(t.time() - start_testing_time, 3)\n",
    "    \n",
    "    print(metrics.classification_report(y, y_pred, digits=2))\n",
    "    print(f'AUC: {metrics.roc_auc_score(y, y_predprob)}')\n",
    "    print(f'Accuracy: {dummy_clf.score(X, y)}')\n",
    "\n",
    "\n",
    "def train_models_Using_TT_split(df_):\n",
    "    results = pd.DataFrame(\n",
    "        columns=['Model', 'AUC', 'Precision', 'Recall', 'F-Score', 'Test_Accuracy',\n",
    "                 'Train_Accuracy', 'Training_time', 'Testing_time'])\n",
    "\n",
    "    df = shuffle(df_)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df[predictors], df[target],\n",
    "                                                        test_size=0.1, stratify=df[target])\n",
    "    X_train_scaled = scale_data_standardscaler(x_train)\n",
    "    X_test_scaled = scale_data_standardscaler(x_test)\n",
    "    classifiers = get_classifiers()\n",
    "    for name, value in classifiers.items():\n",
    "        clf = value\n",
    "        print('Classifier: ', name)\n",
    "        if name == 'XGBoost':\n",
    "            y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_XGB_model(\n",
    "                clf, x_train, y_train, x_test, name)\n",
    "        elif name == 'LinearSVC':\n",
    "            y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_SVM_model(\n",
    "                clf, X_train_scaled, y_train, X_test_scaled, name)\n",
    "        elif name == 'LogisticRegression':\n",
    "            y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_RF_LR_model(\n",
    "                clf, X_train_scaled, y_train, X_test_scaled, name)\n",
    "        elif name == 'MLP':\n",
    "            y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_MLP_model(\n",
    "                clf, X_train_scaled, y_train, X_test_scaled, name)\n",
    "        elif name == 'DT':\n",
    "                y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_RF_LR_model(\n",
    "                    clf, x_train, y_train, x_test, name)\n",
    "        elif name == 'NaiveBayes':\n",
    "            y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_RF_LR_model(\n",
    "                clf, x_train, y_train, x_test, name)\n",
    "        elif name == 'KNN':\n",
    "            y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_RF_LR_model(\n",
    "                clf, x_train, y_train, x_test, name)\n",
    "        else:\n",
    "            y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_RF_LR_model(\n",
    "                clf, x_train, y_train, x_test, name)\n",
    "\n",
    "        print(\"\\nModel Report\")\n",
    "        print(\"Train Accuracy : %.4g\" % metrics.accuracy_score(y_train, y_pred_train))\n",
    "        print(\"Test Accuracy : %.4g\" % metrics.accuracy_score(y_test, y_pred))\n",
    "        print('Train error: {:.3f}'.format(1 - metrics.accuracy_score(y_train, y_pred_train)))\n",
    "        print('Test error: {:.3f}'.format(1 - metrics.accuracy_score(y_test, y_pred)))\n",
    "        print(\"AUC Score : %f\" % metrics.roc_auc_score(y_test, y_predprob))\n",
    "        print(\"Recall : %f\" % metrics.recall_score(y_test, y_pred))\n",
    "        print(\"Precision : %f\" % metrics.precision_score(y_test, y_pred))\n",
    "        print(\"F-measure : %f\" % metrics.f1_score(y_test, y_pred))\n",
    "        # print(metrics.confusion_matrix(y_test, y_pred))\n",
    "        c_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "        print('========Confusion Matrix==========')\n",
    "        print(\"          Smelly    Non-Smelly\")\n",
    "        print('Smelly      {}           {}'.format(c_matrix[0][0], c_matrix[0][1]))\n",
    "        print('Non-Smelly  {}           {}'.format(c_matrix[1][0], c_matrix[1][1]))\n",
    "        results = results.append(\n",
    "            {'Model': name, 'AUC': metrics.roc_auc_score(y_test, y_predprob),\n",
    "             'Precision': metrics.precision_score(y_test, y_pred),\n",
    "             'Recall': metrics.recall_score(y_test, y_pred),\n",
    "             'F-Score': metrics.f1_score(y_test, y_pred),\n",
    "             'Test_Accuracy': metrics.accuracy_score(y_test, y_pred),\n",
    "             'Train_Accuracy': metrics.accuracy_score(y_train, y_pred_train),\n",
    "             'Training_time': training_time,\n",
    "             'Testing_time': testing_time,\n",
    "             }, ignore_index=True)\n",
    "    results.to_csv('Results/results_1.csv',\n",
    "                   sep=',', encoding='utf-8', index=False)\n",
    "    print('CSV files saved...')\n",
    "\n",
    "\n",
    "def train_models_using_10FoldCV(df_):\n",
    "    results = pd.DataFrame(\n",
    "        columns=['Model', 'Fold', 'AUC', 'Precision', 'Recall', 'F-Score', 'Test_Accuracy',\n",
    "                 'Train_Accuracy', 'Training_time', 'Testing_time'])\n",
    "    X = df_[predictors]\n",
    "    y = df_[target]\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, random_state=None, shuffle=True)  \n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        # print(y_train, y_test)\n",
    "        X_train_scaled = scale_data_standardscaler(x_train)\n",
    "        X_test_scaled = scale_data_standardscaler(x_test)\n",
    "\n",
    "        classifiers = get_classifiers()\n",
    "        for name, value in classifiers.items():\n",
    "            clf = value\n",
    "            print('Classifier: ', name)\n",
    "            if name == 'XGBoost':\n",
    "                y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_XGB_model(\n",
    "                    clf, x_train, y_train, x_test, name)\n",
    "            elif name == 'LinearSVC':\n",
    "                y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_SVM_model(\n",
    "                    clf, X_train_scaled, y_train, X_test_scaled, name)\n",
    "            elif name == 'LogisticRegression':\n",
    "                y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_RF_LR_model(\n",
    "                    clf, X_train_scaled, y_train, X_test_scaled, name)\n",
    "            elif name == 'MLP':\n",
    "                y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_MLP_model(\n",
    "                    clf, X_train_scaled, y_train, X_test_scaled, name)\n",
    "            elif name == 'DT':\n",
    "                y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_RF_LR_model(\n",
    "                    clf, x_train, y_train, x_test, name)\n",
    "            elif name == 'NaiveBayes':\n",
    "                y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_RF_LR_model(\n",
    "                    clf, x_train, y_train, x_test, name)\n",
    "            elif name == 'KNN':\n",
    "                y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_RF_LR_model(\n",
    "                    clf, x_train, y_train, x_test, name)\n",
    "            else:\n",
    "                y_pred_train, y_predprob_train, y_pred, y_predprob, training_time, testing_time = train_RF_LR_model(\n",
    "                    clf, x_train, y_train, x_test, name)\n",
    "\n",
    "            print(\"\\nModel Report\")\n",
    "            print(\"Train Accuracy : %.4g\" % metrics.accuracy_score(y_train, y_pred_train))\n",
    "            print(\"Test Accuracy : %.4g\" % metrics.accuracy_score(y_test, y_pred))\n",
    "            print('Train error: {:.3f}'.format(1 - metrics.accuracy_score(y_train, y_pred_train)))\n",
    "            print('Test error: {:.3f}'.format(1 - metrics.accuracy_score(y_test, y_pred)))\n",
    "            print(\"AUC Score : %f\" % metrics.roc_auc_score(y_test, y_predprob))\n",
    "            print(\"Recall : %f\" % metrics.recall_score(y_test, y_pred))\n",
    "            print(\"Precision : %f\" % metrics.precision_score(y_test, y_pred))\n",
    "            print(\"F-measure : %f\" % metrics.f1_score(y_test, y_pred))\n",
    "            # print(metrics.confusion_matrix(y_test, y_pred))\n",
    "            c_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "            print('========Confusion Matrix==========')\n",
    "            print(\"          Smelly    Non-Smelly\")\n",
    "            print('Smelly      {}           {}'.format(c_matrix[0][0], c_matrix[0][1]))\n",
    "            print('Non-Smelly  {}           {}'.format(c_matrix[1][0], c_matrix[1][1]))\n",
    "            fold += 1\n",
    "            results = results.append(\n",
    "                {'Model': name, 'Fold': fold, 'AUC': metrics.roc_auc_score(y_test, y_predprob),\n",
    "                 'Precision': metrics.precision_score(y_test, y_pred),\n",
    "                 'Recall': metrics.recall_score(y_test, y_pred),\n",
    "                 'F-Score': metrics.f1_score(y_test, y_pred),\n",
    "                 'Test_Accuracy': metrics.accuracy_score(y_test, y_pred),\n",
    "                 'Train_Accuracy': metrics.accuracy_score(y_train, y_pred_train),\n",
    "                 'Training_time': training_time,\n",
    "                 'Testing_time': testing_time,\n",
    "                 }, ignore_index=True)\n",
    "    avg_result = pd.DataFrame(columns=['Model', 'AUC', 'Precision', 'Recall', 'F-Score', 'Test_Accuracy',\n",
    "                                       'Train_Accuracy', 'Training_time', 'Testing_time'])\n",
    "    for name, value in classifiers.items():\n",
    "        model_result = results.loc[results.Model == name]\n",
    "        avg_result = avg_result.append(\n",
    "            {'Model': name, 'AUC': model_result['AUC'].mean(),\n",
    "             'Precision': model_result['Precision'].mean(),\n",
    "             'Recall': model_result['Recall'].mean(),\n",
    "             'F-Score': model_result['F-Score'].mean(),\n",
    "             'Test_Accuracy': model_result['Test_Accuracy'].mean(),\n",
    "             'Train_Accuracy': model_result['Train_Accuracy'].mean(),\n",
    "             'Training_time': model_result['Training_time'].mean(),\n",
    "             'Testing_time': model_result['Testing_time'].mean()\n",
    "             },\n",
    "            ignore_index=True)\n",
    "\n",
    "    avg_result.to_csv('Results/10_fold_result_avg_1.csv',\n",
    "                      sep=',', encoding='utf-8', index=False)\n",
    "    results.to_csv('Results/10_fold_results_1.csv',\n",
    "                   sep=',', encoding='utf-8', index=False)\n",
    "    print('CSV files saved...')\n",
    "\n",
    "def Baseline_10FoldCV(X, y): \n",
    "    results = pd.DataFrame(\n",
    "        columns=['Model', 'Fold', 'AUC', 'Precision', 'Recall', 'F-Score', 'Test_Accuracy',\n",
    "                 'Train_Accuracy', 'Training_time', 'Testing_time'])\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, random_state=None, shuffle=True)  \n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "         \n",
    "        \n",
    "        dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "        start_training_time = t.time()\n",
    "        dummy_clf.fit(x_train, y_train)\n",
    "        training_time = round(t.time() - start_training_time, 3)\n",
    "        start_testing_time = t.time()\n",
    "        y_pred = dummy_clf.predict(x_train)\n",
    "        y_predprob = dummy_clf.predict_proba(x_train)[:, 1]\n",
    "        testing_time = round(t.time() - start_testing_time, 3)\n",
    "        \n",
    "        fold += 1\n",
    "        results = results.append(\n",
    "            {'Model': 'Baseline', 'Fold': fold, 'AUC': metrics.roc_auc_score(y_train, y_predprob),\n",
    "             'Precision': metrics.precision_score(y_train, y_pred),\n",
    "             'Recall': metrics.recall_score(y_train, y_pred),\n",
    "             'F-Score': metrics.f1_score(y_train, y_pred),\n",
    "             'Test_Accuracy': dummy_clf.score(x_train, y_train),\n",
    "             'Train_Accuracy': dummy_clf.score(x_train, y_train),\n",
    "             'Training_time': training_time,\n",
    "             'Testing_time': testing_time,\n",
    "             }, ignore_index=True)\n",
    "\n",
    "#         print(metrics.classification_report(y_test, y_pred, digits=2))\n",
    "#         print(f'AUC: {metrics.roc_auc_score(y_test, y_predprob)}')\n",
    "#         print(f'Accuracy: {dummy_clf.score(x_train, y_train)}')\n",
    "    return results\n",
    "\n",
    "def hyperparamGridSearch(df_):  \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(df[predictors], df[target],\n",
    "                                                        test_size=0.1, stratify=df[target])\n",
    "       \n",
    "    X = x_train\n",
    "    y = y_train\n",
    "    X_scaled = scale_data_standardscaler(X)       \n",
    "    kf = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)    \n",
    "    classifiers = get_classifiers_without_params()    \n",
    "    res = []\n",
    "    for name, value in classifiers.items():\n",
    "            clf = value\n",
    "            print('Classifier: ', name)\n",
    "            if name == 'XGBoost':\n",
    "               # define search space\n",
    "                space = dict()\n",
    "                space['n_estimators']= [50, 100, 150, 200]\n",
    "                space['learning_rate'] = [0.01, 0.1, 0.2, 0.3]\n",
    "                space['gamma'] = [i/10.0 for i in range(3)]\n",
    "                space['colsample_bytree'] = [i/10.0 for i in range(1, 3)]\n",
    "                space['max_depth'] = range(3, 10)  \n",
    "#                 space['gamma'] = [0.05, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "#                 space['max_depth'] = [3, 5, 7, 9, 12, 15, 17, 25]\n",
    "#                 space['min_child_weight'] = [1, 3, 5, 7]\n",
    "#                 space['subsample'] = [0.6, 0.7, 0.8, 0.9, 1.0] \n",
    "#                 space['colsample_bytree'] = [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "#                 space['lambda'] = [0.01, 0.1, 1.0]\n",
    "#                 space['alpha'] = [0, 0.1, 0.5, 1.0]                \n",
    "                # define search\n",
    "                search = GridSearchCV(clf, space, scoring='accuracy', cv=kf)               \n",
    "                # execute search\n",
    "                result = search.fit(X, y)\n",
    "                # saving result\n",
    "                record = {'model': name, 'accuracy': result.best_score_}\n",
    "                record.update(result.best_params_)\n",
    "                res.append(record)\n",
    "            elif name == 'LinearSVC':\n",
    "                # define search space\n",
    "                space = dict()\n",
    "#                 space['kernel'] = ['poly', 'rbf', 'sigmoid']\n",
    "                space['C'] = [1e-6, 1e+6, 1.0, 'log-uniform']\n",
    "#                 space['gamma'] = ['scale']\n",
    "                # define search\n",
    "                search = GridSearchCV(clf, space, scoring='accuracy', n_jobs=-1, cv=kf)               \n",
    "                # execute search\n",
    "                result = search.fit(X_scaled, y)\n",
    "                # saving result\n",
    "                record = {'model': name, 'accuracy': result.best_score_}\n",
    "                record.update(result.best_params_) \n",
    "                res.append(record)\n",
    "            elif name == 'LogisticRegression':\n",
    "                # define search space\n",
    "                space = dict()\n",
    "                space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "                space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "                space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]              \n",
    "                # define search\n",
    "                search = GridSearchCV(clf, space, scoring='accuracy', n_jobs=-1, cv=kf)               \n",
    "                # execute search\n",
    "                result = search.fit(X_scaled, y)\n",
    "                # saving result\n",
    "                record = {'model': name, 'accuracy': result.best_score_}\n",
    "                record.update(result.best_params_)  \n",
    "                res.append(record)\n",
    "            elif name == 'BaggedDT':\n",
    "                # define search space\n",
    "                space = dict()\n",
    "                space['n_estimators'] = [10, 100, 1000]             \n",
    "                # define search\n",
    "                search = GridSearchCV(clf, space, scoring='accuracy', n_jobs=-1, cv=kf)               \n",
    "                # execute search\n",
    "                result = search.fit(X, y)\n",
    "                # saving result\n",
    "                record = {'model': name, 'accuracy': result.best_score_}\n",
    "                record.update(result.best_params_)  \n",
    "                res.append(record)\n",
    "            elif name == 'NaiveBayes':\n",
    "                # define search space\n",
    "                space = dict()\n",
    "                space['var_smoothing'] = [1e-9 , np.logspace(0,-9, num=100) ]            \n",
    "                # define search\n",
    "                search = GridSearchCV(clf, space, scoring='accuracy', n_jobs=-1, cv=kf)               \n",
    "                # execute search\n",
    "                result = search.fit(X, y)\n",
    "                # saving result\n",
    "                record = {'model': name, 'accuracy': result.best_score_}\n",
    "                record.update(result.best_params_)  \n",
    "                res.append(record)\n",
    "            elif name == 'KNN':\n",
    "                # define search space\n",
    "                space = dict()\n",
    "                space['n_neighbors'] = range(1, 21, 2)\n",
    "                space['weights'] = ['uniform', 'distance']\n",
    "                space['metric'] = ['euclidean', 'manhattan', 'minkowski']              \n",
    "                # define search\n",
    "                search = GridSearchCV(clf, space, scoring='accuracy', n_jobs=-1, cv=kf)               \n",
    "                # execute search\n",
    "                result = search.fit(X, y)\n",
    "                # saving result\n",
    "                record = {'model': name, 'accuracy': result.best_score_}\n",
    "                record.update(result.best_params_)  \n",
    "                res.append(record)\n",
    "            elif name == 'RandomForest':\n",
    "                # define search space\n",
    "                space = dict()\n",
    "                space['n_estimators'] = [10, 100, 1000]\n",
    "                space['max_features'] = ['sqrt', 'log2']\n",
    "                # define search\n",
    "                search = GridSearchCV(clf, space, scoring='accuracy', n_jobs=-1, cv=kf)               \n",
    "                # execute search\n",
    "                result = search.fit(X, y)\n",
    "                # saving result\n",
    "                record = {'model': name, 'accuracy': result.best_score_}\n",
    "                record.update(result.best_params_) \n",
    "                res.append(record)\n",
    "            elif name == 'MLP':\n",
    "                # define search space\n",
    "#                 space = dict()\n",
    "#                 space['hidden_layer_sizes'] = [(50,50,50), (50,100,50), (100,)],\n",
    "#                 space['activation'] = ['tanh', 'relu'],\n",
    "#                 space['solver'] = ['sgd', 'adam'],\n",
    "#                 space['alpha'] = [0.0001, 0.5],\n",
    "#                 space['learning_rate'] = ['constant','adaptive']\n",
    "                parameter_space = {\n",
    "                    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "                    'activation': ['tanh', 'relu'],\n",
    "                    'solver': ['sgd', 'adam'],\n",
    "                    'alpha': [0.0001, 0.05],\n",
    "                    'learning_rate': ['constant','adaptive'],\n",
    "                }\n",
    "                # define search\n",
    "                search = GridSearchCV(clf, parameter_space, scoring='accuracy', n_jobs=-1, cv=kf)               \n",
    "                # execute search\n",
    "                result = search.fit(X_scaled, y)\n",
    "                # saving result\n",
    "                record = {'model': name, 'accuracy': result.best_score_}\n",
    "                record.update(result.best_params_) \n",
    "                res.append(record)\n",
    "    resdf = pd.DataFrame(res)\n",
    "    resdf.to_csv('Results/hptuning_results.csv',sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print('Processing')\n",
    "\n",
    "    df = df.dropna()\n",
    "    print(df['Project_Name'].unique().tolist())\n",
    "#     hyperparamGridSearch(df)\n",
    "    train_models_using_10FoldCV(df)\n",
    "#     train_baseline_df = Baseline_10FoldCV(df[predictors], df[target])\n",
    "#     baseline_classifer(df[predictors], df[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-desire",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
